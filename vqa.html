<!DOCTYPE html>
<html>
	<head>
		<title>VQA</title>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	</head>
	<body>
		<h1>Visual Question Answering</h1>
		<h2>Introduction</h2>
		<p>
			The VQA is a challenge to provide an accurate natural language answer to a given image and a natural language question. The questions are such that they target different areas of an image, including background details and underlying context. The VQA dataset consists of \(254721\) images (MSCOCO) and \(3\) questions per image. Also, 10 ground truth answers per question are provided out of which we choose only the most likely answer during training. We used Python and Keras for the implemetation. The code is hosted on GitHub. 
		</p>
		<h2> The Model</h2>
		<p>
			
		</p>
	</body>
</html>
